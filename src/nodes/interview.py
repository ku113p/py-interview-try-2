import asyncio
import json
import uuid
from typing import Annotated

from langchain_core.messages import AIMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langgraph.graph.message import add_messages
from pydantic import BaseModel

from src import db


class State(BaseModel):
    area_id: uuid.UUID
    extract_data_tasks: asyncio.Queue[uuid.UUID]
    messages: Annotated[list[BaseMessage], add_messages]
    was_covered: bool

    class Config:
        arbitrary_types_allowed = True


class CriterionCoverage(BaseModel):
    title: str
    covered: bool


class CriteriaCoverageResult(BaseModel):
    criteria: list[CriterionCoverage]
    all_covered: bool
    final_answer: str


async def interview(state: State, llm: ChatOpenAI):
    area_id = state.area_id
    message_content = state.messages[-1].content
    if isinstance(message_content, list):
        message_content = "".join(str(part) for part in message_content)
    elif not isinstance(message_content, str):
        message_content = str(message_content)

    last_area_msg = db.LifeAreaMessage(
        id=uuid.uuid4(),
        data=message_content,
        area_id=area_id,
    )
    db.LifeAreaMessagesManager.create(last_area_msg.id, last_area_msg)

    area_msgs: list[str] = [
        msg.data for msg in db.LifeAreaMessagesManager.list_by_area(area_id)
    ]
    area_criteria: list[str] = [
        c.title for c in db.CriteriaManager.list_by_area(area_id)
    ]

    ai_answer, was_covered = await check_criteria_covered(area_msgs, area_criteria, llm)
    if was_covered:
        await state.extract_data_tasks.put(area_id)

    return {"messages": [AIMessage(content=ai_answer)], "was_covered": was_covered}


async def check_criteria_covered(
    interview_messages: list[str],
    area_criteria: list[str],
    llm: ChatOpenAI,
) -> tuple[str, bool]:
    system_prompt = (
        "You are an interview agent.\n"
        "Your task:\n"
        "1. Decide for EACH criterion whether it is clearly covered by the interview\n"
        "2. If ALL criteria are covered → thank the interviewee and close politely\n"
        "3. If NOT all covered → ask about ONE uncovered criterion (the most logical next one)\n\n"
        "Rules:\n"
        "- Be strict: unclear or partial answers = NOT covered\n"
        "- Ask only ONE question\n"
        "- Be polite, natural, and conversational\n"
    )

    user_prompt = {
        "interview_messages": interview_messages,
        "criteria": area_criteria,
    }

    structured_llm = llm.with_structured_output(CriteriaCoverageResult)

    result = await structured_llm.ainvoke(
        [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_prompt)},
        ]
    )

    if not isinstance(result, CriteriaCoverageResult):
        result = CriteriaCoverageResult.model_validate(result)

    final_answer = result.final_answer
    all_covered = result.all_covered

    return final_answer, all_covered
