import json
import asyncio
import json
from typing import Annotated, TypedDict
import uuid

from langchain_core.messages import AIMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langgraph.graph.message import add_messages

from src import db


class State(TypedDict):
    area_id: uuid.UUID
    extract_data_tasks: asyncio.Queue[uuid.UUID]
    messages: Annotated[list[BaseMessage], add_messages]
    was_covered: bool


async def interview(state: State, llm: ChatOpenAI):
    area_id = state["area_id"]
    message_content = state["messages"][-1].content
    if isinstance(message_content, list):
        message_content = "".join(str(part) for part in message_content)
    elif not isinstance(message_content, str):
        message_content = str(message_content)

    last_area_msg = db.LifeAreaMessageObject(
        id=uuid.uuid4(),
        data=message_content,
        area_id=area_id,
        created_ts=0,
    )
    db.LifeAreaMessages.create(last_area_msg.id, last_area_msg)

    area_msgs: list[str] = [
        msg.data for msg in db.LifeAreaMessages.list_by_area(area_id)
    ]
    area_criteria: list[str] = [c.title for c in db.Criteria.list_by_area(area_id)]

    ai_answer, was_covered = await check_criteria_covered(area_msgs, area_criteria, llm)
    if was_covered:
        await state["extract_data_tasks"].put(area_id)

    return {"messages": [AIMessage(content=ai_answer)], "was_covered": was_covered}


async def check_criteria_covered(
    interview_messages: list[str],
    area_criteria: list[str],
    llm: ChatOpenAI,
) -> tuple[str, bool]:
    system_prompt = (
        "You are an interview agent.\n"
        "Your task:\n"
        "1. Decide for EACH criterion whether it is clearly covered by the interview\n"
        "2. If ALL criteria are covered → thank the interviewee and close politely\n"
        "3. If NOT all covered → ask about ONE uncovered criterion (the most logical next one)\n\n"
        "Rules:\n"
        "- Be strict: unclear or partial answers = NOT covered\n"
        "- Ask only ONE question\n"
        "- Be polite, natural, and conversational\n"
        "- Respond ONLY with valid JSON\n\n"
        "JSON format:\n"
        "{\n"
        '  "criteria": [\n'
        '    {"title": "<criterion>", "covered": true | false}\n'
        "  ],\n"
        '  "all_covered": true | false,\n'
        '  "final_answer": "<assistant message to send to user>"\n'
        "}\n"
    )

    user_prompt = {
        "interview_messages": interview_messages,
        "criteria": area_criteria,
    }

    response = await llm.ainvoke(
        [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_prompt)},
        ]
    )

    if not isinstance(response.content, str):
        raise ValueError("Unexpected response content type")

    data = json.loads(response.content)

    final_answer: str = data.get("final_answer", "")
    all_covered: bool = data.get("all_covered", False)

    return final_answer, all_covered
